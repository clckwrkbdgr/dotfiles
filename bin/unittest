#!/usr/bin/env python
import os, sys, subprocess, platform
try:
	subprocess.DEVNULL
except AttributeError:
	subprocess.DEVNULL = open(os.devnull, 'w')
import re
import itertools
try:
	import configparser
except ImportError:
	import ConfigParser as configparser
try:
	from pathlib2 import Path
except ImportError: # pragma: no cover
	from pathlib import Path
import click
try:
	import termcolor
except ImportError: # pragma: no cover
	import dummy as termcolor
import six
from clckwrkbdgr.unittest.runner import test_suite
import clckwrkbdgr.unittest.python
import clckwrkbdgr.unittest.shell
import clckwrkbdgr.unittest.javascript

def ensure_test_data_dir():
	setup_cfg = configparser.ConfigParser()
	setup_cfg.read(['setup.cfg'])
	if setup_cfg.has_section('unittest'):
		if setup_cfg.has_option('unittest', 'data_dir'):
			data_dir = os.path.expandvars(setup_cfg.get('unittest', 'data_dir'))
			Path(data_dir).expanduser().mkdir(parents=True, exist_ok=True)

@click.command()
@click.argument('tests', nargs=-1)
@click.option('-q', '--quiet', is_flag=True, default=False,
		help='Quiet run (less output, report errors only)')
@click.option('-v', '--verbose', is_flag=True, default=False,
		help='Verbose output.')
@click.option('-p', '--platform', default=['all'], multiple=True,
		type=click.Choice(['all'] + list(test_suite.keys()), case_sensitive=False),
		help='List of testing platforms to execute tests for.')
def main(tests, quiet=False, verbose=False, platform=None):
	""" Runs specified test suites/modules/cases in current directory
	for a number of known platforms/languages.
	See list of supported platforms in --platform option description.
	TESTS are a list of test specifications conforming to Python unittest spec:
	   module.submodule...[.TestClass][.test_case]
	If test specs are omitted, complete discovery is executed (depends on corresponding platform).
	"""
	ensure_test_data_dir()
	tests = tests or [None]

	rc = 0
	for runner_name in test_suite.keys():
		if not ('all' in platform or runner_name in platform):
			continue
		runner = test_suite[runner_name]
		if not quiet:
			test_name = '<autodiscovery>'
			if tests:
				if len(tests) == 1:
					test_name = tests[0]
				else:
					test_name = '{0} tests'.format(len(tests))
			print(termcolor.colored('Running {0} tests for: {1}'.format(runner_name, test_name), 'blue'))
		result = runner(tests, quiet=quiet, verbose=verbose)
		rc += result
		if not quiet:
			if result == 0:
				print(termcolor.colored('Success.', 'green'))
			else:
				print(termcolor.colored('RC: {0}'.format(result), 'red'))
	if not quiet and rc != 0:
		print(termcolor.colored('Total RC: {0}'.format(rc), 'red'))
	sys.exit(rc)

if __name__ == '__main__':
	main()
